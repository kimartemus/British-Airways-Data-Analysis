{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Verified |  A nightmare journey courtesy o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>â Trip Verified | Absolutely atrocious. LHR-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>â Trip Verified | As someone who flies relen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>â Trip Verified |   Flew with British Airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>â Trip Verified |   Straightforward check in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews\n",
       "0           0  Not Verified |  A nightmare journey courtesy o...\n",
       "1           1  â\n",
       " Trip Verified | Absolutely atrocious. LHR-...\n",
       "2           2  â\n",
       " Trip Verified | As someone who flies relen...\n",
       "3           3  â\n",
       " Trip Verified |   Flew with British Airway...\n",
       "4           4  â\n",
       " Trip Verified |   Straightforward check in..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1000 non-null   int64 \n",
      " 1   reviews     1000 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>499.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.819436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>249.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>499.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>749.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0\n",
       "count  1000.000000\n",
       "mean    499.500000\n",
       "std     288.819436\n",
       "min       0.000000\n",
       "25%     249.750000\n",
       "50%     499.500000\n",
       "75%     749.250000\n",
       "max     999.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import re  # Import regular expressions library\n",
    "from ftfy import fix_text  # Import ftfy\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/artemus/Documents/My_Projects/BritishAirways/data/BA_reviews.csv', encoding = \"ISO-8859-1\")\n",
    "print(df.shape)\n",
    "\n",
    "# Display the first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Show basic statistics\n",
    "display(df.info())\n",
    "display(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/artemus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/artemus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/artemus/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Function to remove special characters (non-ASCII)\n",
    "def remove_special_characters(text):\n",
    "    # Remove any character that is not alphanumeric, space, or basic punctuation\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "# Function to clean text by removing special characters and handling encoding\n",
    "def clean_text(text):\n",
    "    # Use ftfy to fix text encoding issues\n",
    "    text = fix_text(text)\n",
    "    \n",
    "    # Convert to ASCII and ignore characters that can't be encoded\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Remove any remaining special characters except basic punctuation\n",
    "    text = re.sub(r'[^\\w\\s.,!?-]', '', text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Remove special characters from the 'reviews' column\n",
    "df['cleaned_reviews'] = df['reviews'].apply(remove_special_characters)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv('cleaned_BA_reviews.csv', index=False)\n",
    "\n",
    "# Put the text in a lower case \n",
    "df['cleaned_reviews'] = df['reviews'].str.lower()\n",
    "\n",
    "# Convert to lowercase\n",
    "df['cleaned_reviews'] = df['reviews'].str.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "df['cleaned_reviews'] = df['cleaned_reviews'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Remove numbers\n",
    "df['cleaned_reviews'] = df['cleaned_reviews'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "# Remove whitespace\n",
    "df['cleaned_reviews'] = df['cleaned_reviews'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Remove stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['cleaned_reviews'] = df['cleaned_reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "# Tokenization\n",
    "nltk.download('punkt')\n",
    "df['tokens'] = df['cleaned_reviews'].apply(word_tokenize)\n",
    "\n",
    "# Lemmatization\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Remove short words\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if len(word) > 2])\n",
    "\n",
    "# Correct spelling\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [str(TextBlob(word).correct()) for word in x])\n",
    "\n",
    "# Rejoin tokens\n",
    "df['cleaned_reviews'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Handle missing or duplicate values\n",
    "df.dropna(subset=['cleaned_reviews'], inplace=True)\n",
    "df.drop_duplicates(subset=['cleaned_reviews'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text by removing special characters and handling encoding\n",
    "def clean_text(text):\n",
    "    # Convert to ASCII and ignore characters that can't be encoded\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Remove any remaining special characters except basic punctuation\n",
    "    text = re.sub(r'[^\\w\\s.,!?-]', '', text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df.to_csv('cleaned_BA_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/artemus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/artemus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def remove_stopwords_nltk(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df.to_csv('cleaned_BA_reviews.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
